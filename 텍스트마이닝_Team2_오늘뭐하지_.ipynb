{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab with Google Drive"
      ],
      "metadata": {
        "id": "kBP9ZhYgetuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUT2c6B_ehYm",
        "outputId": "7df6273d-1e93-4cf1-c6c3-b7832b5116c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "WKFzuUiHfPqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TextMining Team2 - 오늘 뭐하지?**\n",
        "\n",
        "구글 드라이브 링크 -> 공유 폴더를 '드라이브에 바로가기 추가' 하신 뒤 Run ALL 하시면 작동합니다!\n",
        "\n",
        "(모델을 불러오는 과정에서 시간이 조금 소요됩니다)\n",
        "\n",
        "**※ 지원하는 지역 리스트 : [송파구, 중구, 종로구, 용산구, 강남구, 서초구, 서대문구, 동대문구, 마포구, 영등포구, 성동구, 용산구, 광진구]**"
      ],
      "metadata": {
        "id": "5YrOtT5gh5E9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PATH"
      ],
      "metadata": {
        "id": "A51j-OtZfR2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 설정 후 Run all 해주시면 맨 아래 쉘의 코드가 실행됩니다.\n",
        "\n",
        "# 데이터 파일(Dataset)의 경로를 설정해주세요\n",
        "DATA_PATH = '/content/drive/MyDrive/[Team2] TextMining - 오늘 뭐하지?/dataset.csv'\n",
        "\n",
        "# 지하철 데이터 파일(Metro)의 경로를 설정해주세요\n",
        "METRO_PATH = '/content/drive/MyDrive/[Team2] TextMining - 오늘 뭐하지?/지하철_좌표.csv'\n",
        "\n",
        "# 모델 파일의 경로를 설정해주세요\n",
        "MODEL_PATH = '/content/drive/MyDrive/[Team2] TextMining - 오늘 뭐하지?/FastTextModel.bin'"
      ],
      "metadata": {
        "id": "GyS9dHtlfRJE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install"
      ],
      "metadata": {
        "id": "DB8rTPIRexXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install gensim\n",
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5727MuwewhT",
        "outputId": "eb53290b-1e7d-464c-ea60-ab1b9e4481d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "j8jRKurme1_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "Lg0c3y7-e1JK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Seed fix"
      ],
      "metadata": {
        "id": "Am3c7irSe57g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random as python_random # 시드값 고정\n",
        "seed_num = 42\n",
        "np.random.seed(seed_num)\n",
        "python_random.seed(seed_num)"
      ],
      "metadata": {
        "id": "3AoM9QLHe8pi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Import"
      ],
      "metadata": {
        "id": "CIzWMFQxfBds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metro = pd.read_csv(METRO_PATH)\n",
        "data = pd.read_csv(DATA_PATH)\n",
        "data = data.fillna('')\n",
        "\n",
        "food = data[data['구분']=='식당']\n",
        "place = data[data['구분']=='장소']\n",
        "cafe = data[data['구분']=='카페']\n",
        "bar =  data[data['구분']=='술집']"
      ],
      "metadata": {
        "id": "xDGWdN5wfC5A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Import"
      ],
      "metadata": {
        "id": "hjF9D7qWgCLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 Import에 시간이 조금 걸립니다.\n",
        "from gensim.models import fasttext\n",
        "\n",
        "model = fasttext.load_facebook_model(MODEL_PATH, encoding='utf-8')"
      ],
      "metadata": {
        "id": "Z2gUkG9wgB2K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model의 유사 키워드 추출 (중간결과)"
      ],
      "metadata": {
        "id": "lEUwoEvkvPu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "# 유사 키워드 추출\n",
        "\n",
        "word = \"피자\"\n",
        "sim_words_list = model.wv.most_similar([word], topn=100)\n",
        "\n",
        "print(sim_words_list[:10])\n",
        "print(sim_words_list[40:50])\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_1JCvmOvKh-",
        "outputId": "d42f706d-1f56-4f61-ca69-72583169cca6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('피자로', 0.9249041080474854), ('피자집', 0.9222275018692017), ('피자가', 0.9129948616027832), ('피자도', 0.9122931361198425), ('치즈피자', 0.9057206511497498), ('피자가게가', 0.904869556427002), ('반반피자', 0.892049252986908), ('피자와', 0.891700029373169), ('포테이토피자', 0.8916018605232239), ('마늘빵엣지스테이크피자', 0.8908000588417053)]\n",
            "[('치즈떡볶이', 0.8432779312133789), ('아이스크림으로', 0.8428207635879517), ('아이스크림이다', 0.8425928950309753), ('이태리식', 0.8417824506759644), ('레스토랑이다', 0.8417503833770752), ('매콤크림파스타', 0.8415462970733643), ('미스터피자는', 0.8412715196609497), ('더블갈릭바베큐피자', 0.8409932851791382), ('치킨감자', 0.8407616019248962), ('고르곤졸라피자', 0.8405730128288269)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델을 이용한 데이터셋 임베딩"
      ],
      "metadata": {
        "id": "CvA3a5vbvcZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 이용한 데이터셋의 임베딩\n",
        "\n",
        "def add_vectorized_column(df, model):\n",
        "    # '특성' 열의 값을 벡터화하여 'main_vec' 열 추가\n",
        "    df['main_vec'] = df['특성'].apply(lambda x: [model.wv[word] for word in x if word in model.wv])\n",
        "    df['doc_vec'] = df['doc_key'].apply(lambda x: [model.wv[word] for word in x if word in model.wv])\n",
        "\n",
        "    return df\n",
        "\n",
        "food = add_vectorized_column(food, model)\n",
        "cafe = add_vectorized_column(cafe, model)\n",
        "place = add_vectorized_column(place, model)\n",
        "bar = add_vectorized_column(bar, model)"
      ],
      "metadata": {
        "id": "cHEGi9MzvUo-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사용자 입력문장 키워드 추출 함수"
      ],
      "metadata": {
        "id": "Ea7oyLIkgy36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "def extract_keywords(sentence):\n",
        "    # 형태소 분석기 인스턴스 생성\n",
        "    okt = Okt()\n",
        "\n",
        "    # 형태소 분석 수행\n",
        "    morphemes = okt.pos(sentence, stem=True)\n",
        "\n",
        "    # 부사, 형용사, 명사 추출\n",
        "    keywords_main = [word for word, tag in morphemes if tag in ('Noun')]\n",
        "    keywords_sub = [word for word, tag in morphemes if tag in ('Adjective', 'Adverb')]\n",
        "\n",
        "    # 제외하고 싶은 단어들\n",
        "    exclude_words_main = [\"나\", \"오늘\", \"가다\", \"먹다\", \"곳\", \"식당\", \"카페\", '술', '없다', '어떻다', '거나', '음식', '이면', '추천', '걸','건', '것', '땡기다', '약속', '장소', '출발', '안녕','뭔가', '아침', '점심', '저녁','간식','식사','가게','종류','류','게']\n",
        "\n",
        "    # 제외할 동사 및 조사 설정\n",
        "    exclude_verbs_and_josa = ['빼다', '제외하다', '말고', '빼고', '싫다', '싫어', '싫고']\n",
        "\n",
        "    # ~비슷한, ~같은의 키워드가 있는가?\n",
        "    Islike = False\n",
        "\n",
        "    # 이후 검색에서 제외할 키워드\n",
        "    exclude_keywords = []\n",
        "\n",
        "    # '같다' 또는 '비슷하다' 키워드가 있으면 Islike를 True로 설정하고 키워드 제거\n",
        "    for i, (word, tag) in enumerate(morphemes):\n",
        "        if word in ['같다', '같이', '비슷하다']:\n",
        "            Islike = True\n",
        "            # 이전 단어가 명사, 형용사, 부사인 경우 제외 리스트에 추가\n",
        "            j = i - 1\n",
        "            while j >= 0:\n",
        "                if morphemes[j][1] in ('Noun', 'Adjective', 'Adverb'):\n",
        "                    exclude_words_main.append(morphemes[j][0])\n",
        "                    exclude_keywords.append(morphemes[j][0])\n",
        "                    break\n",
        "                j -= 1\n",
        "\n",
        "    # 동사 및 조사를 찾아 그 앞에 있는 명사, 형용사, 부사 제외\n",
        "    for i, (word, tag) in enumerate(morphemes):\n",
        "        if word in exclude_verbs_and_josa:\n",
        "            j = i - 1\n",
        "            # 명사, 형용사, 부사 찾기\n",
        "            while j >= 0:\n",
        "                if morphemes[j][1] in ('Noun', 'Adjective', 'Adverb'):\n",
        "                    exclude_words_main.append(morphemes[j][0])\n",
        "                    exclude_keywords.append(morphemes[j][0])\n",
        "                    break\n",
        "                j -= 1\n",
        "\n",
        "    # 제외된 단어들을 제외한 새로운 리스트 생성\n",
        "    keywords_main = [word for word in keywords_main if word not in exclude_words_main]\n",
        "    keywords_sub = [word for word in keywords_sub if word not in exclude_words_main and word not in exclude_verbs_and_josa]\n",
        "    exclude_keywords = [word for word in exclude_keywords if word not in ['비슷하다', '같다']]\n",
        "\n",
        "    return keywords_main, keywords_sub, exclude_keywords, Islike\n"
      ],
      "metadata": {
        "id": "oBM9jQE5gxZz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 키워드 추출 예시 (중간 결과)"
      ],
      "metadata": {
        "id": "alhxJ7MHhGSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 위의 키워드 추출 결과 확인을 위한 쉘\n",
        "# sentence = input(\"문장을 입력하세요: \")\n",
        "sentence = '나는 오늘 달콤한게 먹고 싶어. 도넛은 빼고'\n",
        "keywords_main, keywords_sub, exclude_keywords, Islike = extract_keywords(sentence)\n",
        "\n",
        "print(\"추출된 주요 키워드 :\", keywords_main)\n",
        "print(\"추출된 추상 키워드 (형용사, 부사) :\", keywords_sub)\n",
        "print(\"제외 키워드 :\", exclude_keywords)\n",
        "print(\"Islike :\", Islike)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a3S7jXohDGY",
        "outputId": "472c6c0c-efce-4178-e80e-1386656141d6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장을 입력하세요: 나는 오늘 달콤한게 먹고 싶어. 도넛은 빼고\n",
            "추출된 주요 키워드 : []\n",
            "추출된 추상 키워드 (형용사, 부사) : ['달콤하다']\n",
            "제외 키워드 : ['도넛']\n",
            "Islike : False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추천 함수"
      ],
      "metadata": {
        "id": "yvNbk-vAgdRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.distance import geodesic\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_distance(row, loc_x, loc_y):\n",
        "    return geodesic((loc_x, loc_y), (row['위도'], row['경도'])).kilometers\n",
        "\n",
        "\n",
        "def calculate_similarity(a, b):\n",
        "    return cosine_similarity([a], [b])[0][0]\n",
        "\n",
        "\n",
        "def calculate_average_top_similarities(word_vec, key_vec):\n",
        "    similarities = []\n",
        "    for w in word_vec:\n",
        "        for k in key_vec:\n",
        "            similarities.append(calculate_similarity(w, k))\n",
        "    similarities.sort(reverse=True)\n",
        "    top_similarities = similarities[:5]\n",
        "    return np.mean(top_similarities)\n",
        "\n",
        "\n",
        "def recommend_rows_based_on_keywords(df, model, keywords_main, keywords_sub, exclude_keywords, Islike, loc_x, loc_y):\n",
        "    # 단계 2: loc_x, loc_y와의 직선 거리가 1.5km 이내인 행으로 tmp_df\n",
        "    df['distance'] = df.apply(calculate_distance, args=(loc_x, loc_y), axis=1)\n",
        "\n",
        "    # 거리가 1.5km 이내인 행만 선택\n",
        "    tmp_df = df[df['distance'] <= 3].copy()\n",
        "\n",
        "    # 단계 3: keywords_main으로 main_word_vec 생성\n",
        "    main_word_vec = [model.wv[word] for word in keywords_main if word in model.wv]\n",
        "\n",
        "    # 단계 4: Islike가 True인 경우, sim_words_list 생성 후 sim_word_vec 생성\n",
        "    if (keywords_main==[]) : Islike =False\n",
        "    if Islike  :\n",
        "        sim_words = model.wv.most_similar(positive=keywords_main, topn=50)\n",
        "        sim_words_list = [word for word, similarity in sim_words[10:15]] + [word for word, similarity in sim_words[40:45]]\n",
        "        sim_word_vec = [model.wv[word] for word in sim_words_list if word in model.wv]\n",
        "\n",
        "    # 단계 6: exclude_keywords가 빈 리스트가 아닌 경우, except_word_vec 생성\n",
        "    if exclude_keywords:\n",
        "        except_word_vec = [model.wv[word] for word in exclude_keywords if word in model.wv]\n",
        "\n",
        "    # 단계 7: keywords_sub가 빈 리스트가 아닌 경우, sub_word_vec 생성\n",
        "    if keywords_sub:\n",
        "        sub_word_vec = [model.wv[word] for word in keywords_sub if word in model.wv]\n",
        "\n",
        "    # 단계 9: main_word_vec과 df의 'main_vec' column 사이의 코사인 유사도 측정\n",
        "    main_sim_list = tmp_df['main_vec'].apply(lambda x: calculate_average_top_similarities(main_word_vec, x))\n",
        "\n",
        "    # 단계 10: sub_word_vec이 존재하는 경우, sub_word_vec과 df의 'doc_vec' column 사이의 코사인 유사도 측정\n",
        "    if keywords_sub:\n",
        "        sub_sim_list = tmp_df['doc_vec'].apply(lambda x: calculate_average_top_similarities(sub_word_vec, x))\n",
        "\n",
        "    # 단계 11: except_word_vec이 존재하는 경우\n",
        "    if exclude_keywords:\n",
        "        except_sim_list_1 = tmp_df['main_vec'].apply(lambda x: calculate_average_top_similarities(except_word_vec, x))\n",
        "        except_sim_list_2 = tmp_df['doc_vec'].apply(lambda x: calculate_average_top_similarities(except_word_vec, x)) if keywords_sub else [0]*len(tmp_df)\n",
        "\n",
        "    # 단계 12: sim_word_vec이 존재하는 경우 (Islike가 True인 경우)\n",
        "    if Islike:\n",
        "        sim_sim_list = tmp_df['main_vec'].apply(lambda x: calculate_average_top_similarities(sim_word_vec, x))\n",
        "\n",
        "    # 단계 13: 리스트들 정렬하고 최종 점수 계산\n",
        "    tmp_df['main_similarity'] = main_sim_list\n",
        "    if keywords_sub:\n",
        "        tmp_df['sub_similarity'] = sub_sim_list\n",
        "    if exclude_keywords:\n",
        "        tmp_df['except_similarity'] = [max(e1, e2) for e1, e2 in zip(except_sim_list_1, except_sim_list_2)]\n",
        "    if Islike:\n",
        "        tmp_df['sim_similarity'] = sim_sim_list\n",
        "\n",
        "\n",
        "    # 최종 점수 계산\n",
        "    if not keywords_main and not keywords_sub and not exclude_keywords:\n",
        "        tmp_df = tmp_df.sample(frac=1).reset_index(drop=True)\n",
        "    else:\n",
        "      if keywords_sub and exclude_keywords and Islike:\n",
        "           tmp_df['final_score'] = tmp_df['main_similarity']*1.7 + tmp_df['sub_similarity']*0.15 - tmp_df['except_similarity'] + tmp_df['sim_similarity']*0.15\n",
        "      elif keywords_sub and exclude_keywords:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']*1.7 + tmp_df['sub_similarity']*0.3 - tmp_df['except_similarity']\n",
        "      if keywords_sub and exclude_keywords and Islike:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']*1.7 + tmp_df['sub_similarity']*0.15 - tmp_df['except_similarity'] + tmp_df['sim_similarity']*0.15\n",
        "      elif keywords_sub and exclude_keywords:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']*1.7 + tmp_df['sub_similarity']*0.3 - tmp_df['except_similarity']\n",
        "      elif keywords_sub and Islike:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']*0.6 + tmp_df['sub_similarity']*0.2 + tmp_df['sim_similarity']*0.2\n",
        "      elif exclude_keywords and Islike:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']*0.94 - tmp_df['except_similarity'] + tmp_df['sim_similarity']*1.06\n",
        "      elif keywords_sub:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']*0.85 + tmp_df['sub_similarity']*0.15\n",
        "      elif exclude_keywords:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity'] - tmp_df['except_similarity']\n",
        "      elif Islike:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']*0.47 + tmp_df['sim_similarity']*0.53\n",
        "      else:\n",
        "          tmp_df['final_score'] = tmp_df['main_similarity']\n",
        "\n",
        "    # 단계 14, 15: 최종 추천\n",
        "    result_df = tmp_df.sort_values(by='final_score', ascending=False)\n",
        "\n",
        "    # 최종 추천된 데이터프레임 반환\n",
        "    return result_df.head(10)"
      ],
      "metadata": {
        "id": "maULk9Q_gbIW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 음식점 추천 항목 예시(중간 결과)"
      ],
      "metadata": {
        "id": "y0ckdNLkyDGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "# 추천 받을 주제의 키워드\n",
        "\n",
        "keyword = '치킨'\n",
        "\n",
        "word_vec = model.wv[[keyword]]\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "663zdI4HyLjQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# 코사인 유사도 계산 함수\n",
        "def calculate_similarity(a, b):\n",
        "    return cosine_similarity([a], [b])[0][0]\n",
        "\n",
        "# 각 행에 대해 상위 5개 코사인 유사도의 평균을 계산하는 함수\n",
        "def calculate_average_top_similarities(word_vec, key_vec):\n",
        "    similarities = []\n",
        "    for w in word_vec:\n",
        "        for k in key_vec:\n",
        "            similarities.append(calculate_similarity(w, k))\n",
        "    similarities.sort(reverse=True)\n",
        "    top_similarities = similarities[:5]\n",
        "    return np.mean(top_similarities)\n",
        "\n",
        "# 데이터프레임의 각 'key_vec'와의 코사인 유사도 계산\n",
        "average_similarities = []\n",
        "for index, row in food.iterrows():\n",
        "    avg_similarity = calculate_average_top_similarities(word_vec, row['main_vec'])\n",
        "    average_similarities.append((index, avg_similarity))\n",
        "\n",
        "# 평균 유사도를 기준으로 내림차순 정렬\n",
        "average_similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# 상위 20개 결과 출력\n",
        "top_20 = average_similarities[:20]\n",
        "for index, avg_similarity in top_20:\n",
        "    print(f\"Index: {index}, Average Similarity: {avg_similarity}, Data: {food.loc[index]['장소명']}\")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVu1SMlEiQNf",
        "outputId": "378919b1-a256-4de7-c022-0b20185a41fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index: 62, Average Similarity: 0.7692724466323853, Data: 장원닭한마리\n",
            "Index: 91, Average Similarity: 0.7692724466323853, Data: 칸나닭집\n",
            "Index: 100, Average Similarity: 0.7692724466323853, Data: 큐스\n",
            "Index: 879, Average Similarity: 0.7692724466323853, Data: 부지깽이\n",
            "Index: 1089, Average Similarity: 0.7692724466323853, Data: 김종용누룽지통닭(한남점)\n",
            "Index: 1187, Average Similarity: 0.7692724466323853, Data: 계림원\n",
            "Index: 1198, Average Similarity: 0.7692724466323853, Data: 찜닭마루\n",
            "Index: 1490, Average Similarity: 0.7692724466323853, Data: 두찜 노원하계점\n",
            "Index: 1593, Average Similarity: 0.7692724466323853, Data: 일미리 금계찜닭 가재울점\n",
            "Index: 1628, Average Similarity: 0.7692724466323853, Data: 밥꼬찜닭\n",
            "Index: 1641, Average Similarity: 0.7692724466323853, Data: 동궁찜닭 서교점\n",
            "Index: 1683, Average Similarity: 0.7692724466323853, Data: 두찜성동왕십리점\n",
            "Index: 1832, Average Similarity: 0.7692724466323853, Data: 성식이네 매운닭발\n",
            "Index: 1901, Average Similarity: 0.7692724466323853, Data: 오늘통닭(동대문역사문화공원역점)\n",
            "Index: 2011, Average Similarity: 0.7692724466323853, Data: 두찜 신촌점\n",
            "Index: 2059, Average Similarity: 0.7692724466323853, Data: 대포찜닭\n",
            "Index: 2234, Average Similarity: 0.7692724466323853, Data: 홍대닭갈비2\n",
            "Index: 2273, Average Similarity: 0.7692724466323853, Data: 동궁찜닭 공덕점\n",
            "Index: 2463, Average Similarity: 0.7692724466323853, Data: 추억이닭\n",
            "Index: 2510, Average Similarity: 0.7692724466323853, Data: 테트리스 찜닭 2호점\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CF9FzLQPy86g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **- 오늘 뭐하지? -**"
      ],
      "metadata": {
        "id": "gHRMZCvYzHwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 실행 코드"
      ],
      "metadata": {
        "id": "qXYPB2Figj6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# 추천 결과\n",
        "food_final = None\n",
        "cafe_final = None\n",
        "place_final = None\n",
        "bar_final = None\n",
        "\n",
        "flagFood = 1\n",
        "flagCafe = 1\n",
        "flagPlace = 1\n",
        "flagBar = 1\n",
        "\n",
        "def extract_stations(text):\n",
        "    # \"OO역\" 또는 \"OO OO역\"을 찾는 정규 표현식\n",
        "    pattern = re.compile(r'\\b\\w+(?:\\s\\w+)?역\\b')\n",
        "\n",
        "    # text에서 패턴에 일치하는 문자열 탐색\n",
        "    matches = pattern.findall(text)\n",
        "\n",
        "    # 띄어쓰기 제거 후 일치하는 문자열 반환\n",
        "    stations = [match.replace(\" \", \"\") for match in matches]\n",
        "\n",
        "    # 일치하는 문자열 반환\n",
        "    return stations[0]\n",
        "\n",
        "def x_check(usrInput):\n",
        "    if (usrInput == 'X' or usrInput == 'x'):\n",
        "        return\n",
        "\n",
        "def extract_integers(text):\n",
        "    pattern = re.compile(r'\\d+')  # 정수를 찾는 정규 표현식\n",
        "    integers = pattern.findall(text)  # 문자열에서 정수 추출\n",
        "    return [int(num) for num in integers]  # 추출된 정수들을 정수형으로 변환하여 반환\n",
        "\n",
        "print(\"안녕하세요! 멋진 하루를 보낼 수 있도록 도와드리겠습니다!\\n\")\n",
        "print(\"오늘 어디를 방문하실 계획인가요? 방문 계획이 있다면 인근 지하철 역을 말씀해주시겠어요? \\n(지하철 역 입력을 원하지 않으시면 X를 입력해주세요)\\n\")\n",
        "while(1):\n",
        "  user_loc = input()\n",
        "  if (user_loc == 'X' or user_loc == 'x'):\n",
        "      user_loc = extract_stations('강남역')\n",
        "      loc_x = metro[metro['역명']==user_loc]['위도'].values[0]\n",
        "      loc_y = metro[metro['역명']==user_loc]['경도'].values[0]\n",
        "      break\n",
        "  else:\n",
        "    try:\n",
        "      user_loc = extract_stations(user_loc)\n",
        "      loc_x = metro[metro['역명']==user_loc]['위도'].values[0]\n",
        "      loc_y = metro[metro['역명']==user_loc]['경도'].values[0]\n",
        "      break\n",
        "    except:\n",
        "      print(\"역 이름을 제대로 입력해주세요\\n\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n감사합니다! 그럼 이제 일정을 세워보겠습니다!\")\n",
        "print(\"금강산도 식후경! 우선 밥을 먹는 것은 어떨까요? 드시고 싶은 음식의 느낌을 자유롭게 적어주세요. \\n(식당 추천을 원하지 않으시면 X를 입력해주세요)\\n\")\n",
        "\n",
        "while(1):\n",
        "  food_sentence = input()\n",
        "  if (food_sentence == 'X' or food_sentence == 'x'):\n",
        "      flagFood = 0\n",
        "      break\n",
        "  else:\n",
        "    try:\n",
        "      keywords_main, keywords_sub, exclude_keywords, Islike = extract_keywords(food_sentence)\n",
        "      food_rec = recommend_rows_based_on_keywords(df=food, model=model, keywords_main=keywords_main, keywords_sub=keywords_sub, exclude_keywords=exclude_keywords, Islike=Islike, \\\n",
        "                                                  loc_x=loc_x, loc_y=loc_y)\n",
        "      break\n",
        "    except:\n",
        "      print(\"죄송합니다. 문장을 이해할 수 없습니다. 다시 입력해주세요.\\n\")\n",
        "\n",
        "if flagFood == 1:\n",
        "  print(\"\\n말씀해주신 결과를 바탕으로 다음과 같은 식당들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\\n\")\n",
        "\n",
        "  place_name =[]\n",
        "  for i in range(len(food_rec)):\n",
        "      place_name = food_rec.iloc[i, :]['장소명']\n",
        "      menu_name = food_rec.iloc[i, :]['대표메뉴'].split(',', 2)[:2]\n",
        "      score = food_rec.iloc[i, :]['final_score']\n",
        "      print(\"[{}번] 장소명: {}, 대표메뉴: {}\".format(i+1, place_name, menu_name))\n",
        "      i = i + 1\n",
        "\n",
        "  if len(place_name) == 0 : # 추천지 중 거리 내에 있는 추천지가 없는 경우\n",
        "    print('죄송합니다ㅠㅠ 조건을 만족하는 추천지가 없습니다!\\n')\n",
        "\n",
        "  else :\n",
        "    while(1):\n",
        "      try:\n",
        "        food_selection = input()\n",
        "        food_selection = extract_integers(food_selection)\n",
        "        food_final = food_rec.iloc[food_selection[0] - 1,:]\n",
        "        break\n",
        "      except:\n",
        "        print(\"제대로 된 번호를 입력해주세요! (예시: 3번)\\n\")\n",
        "\n",
        "    loc_x = food_final['위도']\n",
        "    loc_y = food_final['경도']\n",
        "\n",
        "\n",
        "print(\"\\n느낌있는 카페는 어떠신가요? 카페에 대해 자유롭게 적어주세요 \\n(카페 추천을 원하지 않으시면 X를 입력해주세요)\\n\")\n",
        "\n",
        "while(1):\n",
        "  cafe_sentence = input()\n",
        "  if (cafe_sentence == 'X' or cafe_sentence == 'x'):\n",
        "      flagCafe = 0\n",
        "      break\n",
        "  else:\n",
        "    try:\n",
        "      keywords_main, keywords_sub, exclude_keywords, Islike = extract_keywords(cafe_sentence)\n",
        "      cafe_rec = recommend_rows_based_on_keywords(df=cafe, model=model, keywords_main=keywords_main, keywords_sub=keywords_sub, exclude_keywords=exclude_keywords, Islike=Islike, \\\n",
        "                                                  loc_x=loc_x, loc_y=loc_y)\n",
        "      break\n",
        "    except:\n",
        "      print(\"죄송합니다. 문장을 이해할 수 없습니다. 다시 입력해주세요.\\n\")\n",
        "\n",
        "if flagCafe == 1:\n",
        "    print(\"\\n말씀해주신 결과를 바탕으로 다음과 같은 카페들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\\n\")\n",
        "\n",
        "    place_name =[]\n",
        "    for i in range(len(cafe_rec)):\n",
        "        place_name = cafe_rec.iloc[i, :]['장소명']\n",
        "        menu_name = cafe_rec.iloc[i, :]['대표메뉴'].split(',', 2)[:2]\n",
        "        score = cafe_rec.iloc[i, :]['final_score']\n",
        "        print(\"[{}번] 장소명: {}, 대표메뉴: {}\".format(i+1, place_name, menu_name))\n",
        "        i = i + 1\n",
        "    if len(place_name) == 0 :\n",
        "      print('죄송합니다ㅠㅠ 조건을 만족하는 추천지가 없습니다!\\n')\n",
        "\n",
        "    else :\n",
        "      while(1):\n",
        "        try:\n",
        "          cafe_selection = input()\n",
        "          cafe_selection = extract_integers(cafe_selection)\n",
        "          cafe_final = cafe_rec.iloc[cafe_selection[0] - 1,:]\n",
        "          break\n",
        "        except:\n",
        "          print(\"제대로 된 번호를 입력해주세요! (예시: 3번)\\n\")\n",
        "\n",
        "      loc_x = cafe_final['위도']\n",
        "      loc_y = cafe_final['경도']\n",
        "\n",
        "\n",
        "print(\"\\n재미있는 액티비티나 문화생활을 즐겨보실래요? 가고 싶은 장소에 대한 느낌을 자유롭게 적어주세요\\n(장소 추천을 원하지 않으시면 X를 입력해주세요)\\n\")\n",
        "\n",
        "while(1):\n",
        "  place_sentence = input()\n",
        "  if (place_sentence == 'X' or place_sentence == 'x'):\n",
        "      flagPlace = 0\n",
        "      break\n",
        "  else:\n",
        "    try:\n",
        "      keywords_main, keywords_sub, exclude_keywords, Islike = extract_keywords(place_sentence)\n",
        "      place_rec = recommend_rows_based_on_keywords(df=place, model=model, keywords_main=keywords_main, keywords_sub=keywords_sub, exclude_keywords=exclude_keywords, Islike=Islike, \\\n",
        "                                                  loc_x=loc_x, loc_y=loc_y)\n",
        "      break\n",
        "    except:\n",
        "      print(\"죄송합니다. 문장을 이해할 수 없습니다. 다시 입력해주세요.\\n\")\n",
        "\n",
        "if flagPlace == 1:\n",
        "    print(\"\\n말씀해주신 결과를 바탕으로 다음과 같은 장소들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\\n\")\n",
        "\n",
        "    place_name =[]\n",
        "    for i in range(len(place_rec)):\n",
        "        place_name = place_rec.iloc[i, :]['장소명']\n",
        "        menu_name = place_rec.iloc[i, :]['업종']\n",
        "        score = place_rec.iloc[i, :]['final_score']\n",
        "\n",
        "        print(\"[{}번] 장소명: {}, 업종: {}\".format(i+1, place_name, menu_name))\n",
        "        i = i + 1\n",
        "    if len(place_name) == 0 :\n",
        "      print('죄송합니다ㅠㅠ 조건을 만족하는 추천지가 없습니다!')\n",
        "\n",
        "    else :\n",
        "      while(1):\n",
        "        try:\n",
        "          place_selection = input()\n",
        "          place_selection = extract_integers(place_selection)\n",
        "          place_final = place_rec.iloc[place_selection[0] - 1,:]\n",
        "          break\n",
        "        except:\n",
        "          print(\"제대로 된 번호를 입력해주세요! (예시: 3번)\\n\")\n",
        "\n",
        "      loc_x = place_final['위도']\n",
        "      loc_y = place_final['경도']\n",
        "\n",
        "\n",
        "print(\"\\n마지막으로 아직 아쉽다면 마무리로 술집은 어떠신가요? 가고 싶은 술집에 대해 자유롭게 적어주세요 \\n(술집 추천을 원하지 않으시면 X를 입력해주세요)\\n\")\n",
        "\n",
        "while(1):\n",
        "  bar_sentence = input()\n",
        "  if (bar_sentence == 'X' or bar_sentence == 'x'):\n",
        "      flagBar = 0\n",
        "      break\n",
        "  else:\n",
        "    try:\n",
        "      keywords_main, keywords_sub, exclude_keywords, Islike = extract_keywords(bar_sentence)\n",
        "      bar_rec = recommend_rows_based_on_keywords(df=bar, model=model, keywords_main=keywords_main, keywords_sub=keywords_sub, exclude_keywords=exclude_keywords, Islike=Islike, \\\n",
        "                                                  loc_x=loc_x, loc_y=loc_y)\n",
        "      break\n",
        "    except:\n",
        "      print(\"죄송합니다. 문장을 이해할 수 없습니다. 다시 입력해주세요.\\n\")\n",
        "\n",
        "if flagBar == 1:\n",
        "    print(\"\\n말씀해주신 결과를 바탕으로 다음과 같은 장소들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\\n\")\n",
        "\n",
        "    place_name =[]\n",
        "    for i in range(len(bar_rec)):\n",
        "        place_name = bar_rec.iloc[i, :]['장소명']\n",
        "        menu_name = bar_rec.iloc[i, :]['대표메뉴'].split(',', 2)[:2]\n",
        "        score = bar_rec.iloc[i, :]['final_score']\n",
        "        print(\"[{}번] 장소명: {}, 대표메뉴: {}\".format(i+1, place_name, menu_name))\n",
        "        i = i + 1\n",
        "    if len(place_name) == 0 :\n",
        "      print('죄송합니다ㅠㅠ 조건을 만족하는 추천지가 없습니다!\\n')\n",
        "\n",
        "    else :\n",
        "      while(1):\n",
        "        try:\n",
        "          bar_selection = input()\n",
        "          bar_selection = extract_integers(bar_selection)\n",
        "          bar_final = bar_rec.iloc[bar_selection[0] - 1,:]\n",
        "          break\n",
        "        except:\n",
        "          print(\"제대로 된 번호를 입력해주세요! (예시: 3번)\\n\")\n",
        "\n",
        "      loc_x = bar_final['위도']\n",
        "      loc_y = bar_final['경도']\n",
        "\n",
        "\n",
        "print(\"\\n감사합니다~ 오늘 일정에 대해 정리해드리겠습니다!\\n\")\n",
        "rec_list = []\n",
        "\n",
        "# 선택한 일정 체크\n",
        "if food_final is not None and not food_final.empty:\n",
        "    rec_list.append(\"식당\")\n",
        "\n",
        "if cafe_final is not None and not cafe_final.empty:\n",
        "    rec_list.append(\"카페\")\n",
        "\n",
        "if place_final is not None and not place_final.empty:\n",
        "    rec_list.append(\"장소\")\n",
        "\n",
        "if bar_final is not None and not bar_final.empty:\n",
        "    rec_list.append(\"술집\")\n",
        "\n",
        "\n",
        "# rec_list에 담긴 각 항목에 대해 처리\n",
        "for rec in rec_list:\n",
        "    # rec가 \"식당\"일 경우\n",
        "    if rec == \"식당\" and not food_final.empty:\n",
        "        row = food_final.copy()  # food_final 데이터프레임의 첫 번째 행\n",
        "        menus = row['대표메뉴']\n",
        "        print(f\"{rec}: {row['장소명']} / 대표메뉴: {menus} / 주소: {row['주소']}\")\n",
        "\n",
        "    # rec가 \"카페\"일 경우\n",
        "    elif rec == \"카페\" and not cafe_final.empty:\n",
        "        row = cafe_final.copy()  # cafe_final 데이터프레임의 첫 번째 행\n",
        "        menus = row['대표메뉴']\n",
        "        print(f\"{rec}: {row['장소명']} / 대표메뉴: {menus} / 주소: {row['주소']}\")\n",
        "\n",
        "    # rec가 \"장소\"일 경우\n",
        "    elif rec == \"장소\" and not place_final.empty:\n",
        "        row = place_final.copy()  # place_final 데이터프레임의 첫 번째 행\n",
        "        print(f\"{rec}: {row['장소명']} / 주소: {row['주소']}\")\n",
        "\n",
        "    # rec가 \"술집\"일 경우\n",
        "    elif rec == \"술집\" and not bar_final.empty:\n",
        "        row = bar_final.copy()  # bar_final 데이터프레임의 첫 번째 행\n",
        "        menus = row['대표메뉴']\n",
        "        print(f\"{rec}: {row['장소명']} / 대표메뉴: {menus} / 주소: {row['주소']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY7nJXZxgf-a",
        "outputId": "dba08dfa-0876-46b7-d1c8-922a5b7fe2ad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요! 멋진 하루를 보낼 수 있도록 도와드리겠습니다!\n",
            "\n",
            "오늘 어디를 방문하실 계획인가요? 방문 계획이 있다면 인근 지하철 역을 말씀해주시겠어요? \n",
            "(지하철 역 입력을 원하지 않으시면 X를 입력해주세요)\n",
            "\n",
            "잠실역\n",
            "\n",
            "감사합니다! 그럼 이제 일정을 세워보겠습니다!\n",
            "금강산도 식후경! 우선 밥을 먹는 것은 어떨까요? 드시고 싶은 음식의 느낌을 자유롭게 적어주세요. \n",
            "(식당 추천을 원하지 않으시면 X를 입력해주세요)\n",
            "\n",
            "따뜻하고 든든한 음식 없을까? 양식이나 한식같은거\n",
            "\n",
            "말씀해주신 결과를 바탕으로 다음과 같은 식당들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\n",
            "\n",
            "[1번] 장소명: greasy house, 대표메뉴: ['갈릭 햄버그 스테이크', ' 슬로피조 햄버그 스테이크']\n",
            "[2번] 장소명: 블랭크, 대표메뉴: ['블랭크 크로플', ' 라비나치즈케이크']\n",
            "[3번] 장소명: 고고생고기, 대표메뉴: ['고고모둠', ' 하이포크 생삼겹 ']\n",
            "[4번] 장소명: 다샤브 송파점, 대표메뉴: ['샤브샤브 인세트', ' 샤브샤브 얼큰커플세트']\n",
            "[5번] 장소명: 경리단길 미트파이(잠실점), 대표메뉴: ['비프치즈파이 ', ' 치킨치즈파이 ']\n",
            "[6번] 장소명: 오브제, 대표메뉴: ['딸기듬뿍 생딸기케이크', ' 로투스치즈케이크']\n",
            "[7번] 장소명: 맘스터치 송파마천점, 대표메뉴: ['탄두리싸이버거', ' 마라싸이버거']\n",
            "[8번] 장소명: 맘스터치, 대표메뉴: ['탄두리싸이버거', ' 마라싸이버거']\n",
            "[9번] 장소명: 터치, 대표메뉴: ['탄두리싸이버거', ' 마라싸이버거']\n",
            "[10번] 장소명: 맘스터치 위례중앙점, 대표메뉴: ['탄두리싸이버거', ' 마라싸이버거']\n",
            "1번\n",
            "\n",
            "느낌있는 카페는 어떠신가요? 카페에 대해 자유롭게 적어주세요 \n",
            "(카페 추천을 원하지 않으시면 X를 입력해주세요)\n",
            "\n",
            "조용하고 디저트가 맛있는 카페\n",
            "\n",
            "말씀해주신 결과를 바탕으로 다음과 같은 카페들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\n",
            "\n",
            "[1번] 장소명: 엘스카페, 대표메뉴: ['얼그레이 쉬폰케이크 호', ' 얼그레이 쉬폰케이크 호']\n",
            "[2번] 장소명: 이디야커피 방이역점, 대표메뉴: ['달고나 믹스치노', ' 크림샷 라떼 세트']\n",
            "[3번] 장소명: 로코코 커피, 대표메뉴: ['인절미토스트셋트', ' 십전대보차']\n",
            "[4번] 장소명: 케키하우스, 대표메뉴: ['보틀케이크미디엄', ' 옥수푸딩']\n",
            "[5번] 장소명: 미미커피숍, 대표메뉴: ['바스크치즈케이크', ' 호밀빵오픈아보카도토스트']\n",
            "[6번] 장소명: COFFEE MIMI(커피미미), 대표메뉴: ['바스크치즈케이크', ' 호밀빵오픈아보카도토스트']\n",
            "[7번] 장소명: 아이스걸크림보이 잠실점, 대표메뉴: ['가지맛 컵', ' ']\n",
            "[8번] 장소명: 빽다방 오금역점, 대표메뉴: ['바나나밀크쉐이크', ' 아메리카노']\n",
            "[9번] 장소명: 김대기 커피스쿨, 대표메뉴: ['파나마 에스메랄다 게이샤 ', ' 스페셜커피원두 ']\n",
            "[10번] 장소명: Pat a cake(팻어케이크), 대표메뉴: ['당일홀케이크', ' 조각모둠홀케이크']\n",
            "3번\n",
            "\n",
            "재미있는 액티비티나 문화생활을 즐겨보실래요? 가고 싶은 장소에 대한 느낌을 자유롭게 적어주세요\n",
            "(장소 추천을 원하지 않으시면 X를 입력해주세요)\n",
            "\n",
            "스트레스가 풀릴만한 신나는 곳\n",
            "\n",
            "말씀해주신 결과를 바탕으로 다음과 같은 장소들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\n",
            "\n",
            "[1번] 장소명: 롯데월드 아이스링크, 업종: 아이스링크\n",
            "[2번] 장소명: 송파어린이영어도서관, 업종: 어린이도서관\n",
            "[3번] 장소명: 롯데월드 시네마, 업종: 이탈리아음식\n",
            "[4번] 장소명: 사각사각 플레이스, 업종: 문화시설\n",
            "[5번] 장소명: 롯데월드 가든스테이지, 업종:  \n",
            "[6번] 장소명: 서울시농수산식품공사 가락몰 쿠킹스튜디오, 업종:  \n",
            "[7번] 장소명: 롯데월드 아쿠아리움, 업종: 아쿠아리움\n",
            "[8번] 장소명: 강남스포츠문화센터, 업종: 스포츠센터\n",
            "[9번] 장소명: SETEC전시장(서울무역전시장), 업종: 컨벤션센터\n",
            "[10번] 장소명: 케이움 갤러리 , 업종: 갤러리,화랑\n",
            "1번\n",
            "\n",
            "마지막으로 아직 아쉽다면 마무리로 술집은 어떠신가요? 가고 싶은 술집에 대해 자유롭게 적어주세요 \n",
            "(술집 추천을 원하지 않으시면 X를 입력해주세요)\n",
            "\n",
            "안주가 맛있는 곳에 가고 싶어\n",
            "\n",
            "말씀해주신 결과를 바탕으로 다음과 같은 장소들을 찾아보았습니다! 마음에 드는 번호를 입력해주세요\n",
            "\n",
            "[1번] 장소명: 지금 보고싶다, 대표메뉴: ['플레이트', ' 플레이트']\n",
            "[2번] 장소명: 구대륙, 대표메뉴: ['구대륙 모듬플레이트', ' 치즈플레이트']\n",
            "[3번] 장소명: 사케쇼프, 대표메뉴: ['사시미플레이트', ' 우니플레이트']\n",
            "[4번] 장소명: 연어는 옳다, 대표메뉴: ['숙성생연어사시미 ', ' 숙성생연어사시미']\n",
            "[5번] 장소명: 명불허전 원조 골뱅이, 대표메뉴: ['골뱅이모둠탕', ' 골뱅이무침 ']\n",
            "[6번] 장소명: 주점금붕어, 대표메뉴: ['장별동 시그니처 닭구이', ' 수비드수육과 볶음김치']\n",
            "[7번] 장소명: 쏘닭(석촌호수), 대표메뉴: ['전기구이통닭 마리', ' 사천깐풍치킨']\n",
            "[8번] 장소명: 호시아이, 대표메뉴: ['호시아이 오마카세', ' 모둠사시미세트']\n",
            "[9번] 장소명: 진식주, 대표메뉴: ['이베리코 베요타 어깻살구이', ' 트러플 감자전']\n",
            "[10번] 장소명: 버들골 이야기, 대표메뉴: ['랍스타조개찜', ' 해물떡볶이']\n",
            "3번\n",
            "\n",
            "감사합니다~ 오늘 일정에 대해 정리해드리겠습니다!\n",
            "\n",
            "식당: greasy house / 대표메뉴: 갈릭 햄버그 스테이크, 슬로피조 햄버그 스테이크, 스모크드 베이컨 햄버그 스테이크, 클래식 베이컨 치즈버거 / 주소: 서울특별시 송파구 백제고분로41길 43-17, 지상1층 (송파동)\n",
            "카페: 로코코 커피 / 대표메뉴: 인절미토스트셋트, 십전대보차, 블루레몬에이드, 아포카토 / 주소: 서울특별시 송파구 충민로 66, 가든파이브라이프 L-6127,6128,6129,6130호 (문정동)\n",
            "장소: 롯데월드 아이스링크 / 주소: 송파구 올림픽로 240\n",
            "술집: 사케쇼프 / 대표메뉴: 사시미플레이트, 우니플레이트, 전복내장파스타, 도미머리조림 / 주소: 서울특별시 송파구 백제고분로45길 24-18, 1층 101호 (송파동)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**※ 지원하는 지역 리스트 : [송파구, 중구, 종로구, 용산구, 강남구, 서초구, 서대문구, 동대문구, 마포구, 영등포구, 성동구, 용산구, 광진구]**\n",
        "\n",
        "**+ 문장에 포함된 (잠재 + 메인) 키워드의 수가 늘어날수록 탐색 시간도 길어집니다!**\n",
        "\n",
        "**테스트에 참고해주세요!**"
      ],
      "metadata": {
        "id": "fjra4Fk8WYjc"
      }
    }
  ]
}